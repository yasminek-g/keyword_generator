{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/kroknes/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered, de-duplicated, and cleaned titles have been saved to 'filtered_stem_lectures.json'\n",
      "Final cleaned course titles have been saved to 'filtered_stem_lectures.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "# Define lecture-related stopwords and patterns to filter out\n",
    "additional_stop_words = {\n",
    "    \"introduction\", \"overview\", \"basics\", \"principles\", \"fundamentals\", \"essentials\",\n",
    "    \"concepts\", \"topics\", \"outline\", \"scope\", \"insights\", \"lecture\", \"session\",\n",
    "    \"class\", \"seminar\", \"discussion\", \"tutorial\", \"workshop\", \"exercise\", \"module\",\n",
    "    \"part\", \"series\", \"unit\", \"goals\", \"objectives\", \"summary\", \"review\", \"highlights\",\n",
    "    \"conclusion\", \"recap\", \"continued\", \"continuation\", \"advanced\", \"update\", \"notes\",\n",
    "    \"refresher\", \"start\", \"beginning\", \"end\", \"final\", \"first\", \"second\", \"third\", \n",
    "    \"perspective\", \"focus\", \"study\", \"methods\", \"approaches\", \"applications\", \"field\",\n",
    "    \"understanding\", \"applications of\", \"in context\", \"applied\", \"introduction to\", \n",
    "    \"explanation\", \"examining\", \"exam\", \"goals\"\n",
    "}\n",
    "all_stopwords = set(stopwords.words(\"english\")).union(additional_stop_words)\n",
    "\n",
    "# Pattern to remove numbers followed by punctuation\n",
    "patterns_to_remove = r\"Lecture\\s*\\d+:|Lecture\\s*\\d+|^(\\d+[\\.\\:\\;\\,\\-\\—\\—]\\s*)\"\n",
    "\n",
    "# Pattern to exclude entries with '(cont.)', '(contd)', '(continued)', etc.\n",
    "continuation_pattern = r\"\\b(cont\\.?|contd\\.?|continued)\\b\"\n",
    "\n",
    "# Pattern to remove any text within parentheses, punctuation, and Roman numerals\n",
    "parentheses_pattern = r\"\\(.*?\\)\"\n",
    "punctuation_pattern = r\"\\b\\w*[^\\w\\s]\\w*\\b\"\n",
    "roman_numeral_pattern = r\"\\b[IVXLCDM]+\\b\"\n",
    "\n",
    "\n",
    "with open('lecture_videos_data.json', 'r') as file:\n",
    "    stem_data = json.load(file)\n",
    "\n",
    "# Function to pre-process and clean the title field\n",
    "def preprocess_title(title):\n",
    "    # Remove parentheses content\n",
    "    title = re.sub(parentheses_pattern, \"\", title)\n",
    "    # Remove words with punctuation\n",
    "    title = re.sub(punctuation_pattern, \"\", title)\n",
    "    # Remove Roman numerals\n",
    "    title = re.sub(roman_numeral_pattern, \"\", title, flags=re.IGNORECASE)\n",
    "    # Remove specified patterns and numbers with punctuation\n",
    "    title = re.sub(patterns_to_remove, \"\", title, flags=re.IGNORECASE)\n",
    "    return title.strip()\n",
    "\n",
    "\n",
    "# Function to filter and separate keywords within title fields\n",
    "def filter_keywords(title):\n",
    "    # Preprocess the title before splitting\n",
    "    title = preprocess_title(title)\n",
    "    # Split by common delimiters and whitespace to separate concepts\n",
    "    title_parts = re.split(r'[,:;\\s]', title)\n",
    "    # Filter out stopwords and unwanted terms in each part\n",
    "    filtered_parts = [\n",
    "        word.strip() for word in title_parts\n",
    "        if word.lower() not in all_stopwords and len(word) > 2 and not word.isdigit()\n",
    "    ]\n",
    "    return filtered_parts\n",
    "\n",
    "\n",
    "# Process JSON data to filter out keywords in the title field and exclude continuation entries\n",
    "unique_lectures = {}\n",
    "for category, lectures in stem_data.items():\n",
    "    filtered_lectures = []\n",
    "    seen_titles = set()\n",
    "    for lecture in lectures:\n",
    "        # Skip titles containing continuation markers\n",
    "        if re.search(continuation_pattern, lecture[\"title\"], re.IGNORECASE):\n",
    "            continue\n",
    "        \n",
    "        # Process title to filter keywords and separate by spaces and punctuation\n",
    "        filtered_title_list = filter_keywords(lecture[\"title\"])\n",
    "        \n",
    "        # Exclude empty titles after filtering\n",
    "        if not filtered_title_list:\n",
    "            continue\n",
    "        \n",
    "        # Create a unique key based on resource_course_title and filtered title list\n",
    "        unique_key = (lecture[\"resource_course_title\"], tuple(filtered_title_list))\n",
    "        if unique_key not in seen_titles:\n",
    "            lecture[\"title\"] = filtered_title_list  # Store the title as a list of separated concepts\n",
    "            filtered_lectures.append(lecture)\n",
    "            seen_titles.add(unique_key)\n",
    "            \n",
    "    unique_lectures[category] = filtered_lectures\n",
    "\n",
    "with open('filtered_stem_lectures.json', 'w') as outfile:\n",
    "    json.dump(unique_lectures, outfile, indent=4)\n",
    "\n",
    "print(\"Filtered, de-duplicated, and cleaned titles have been saved to 'filtered_stem_lectures.json'\")\n",
    "\n",
    "\n",
    "# Filter the resource_course_title field in the saved filtered data\n",
    "introductory_phrases = [\n",
    "    r\"Introduction to\", r\"Principles of\", r\"Basics of\", r\"Overview of\",\n",
    "    r\"Essentials of\", r\"Introduction\", r\"Intro to\", r\"Introductory\", r\"Foundations of\"\n",
    "]\n",
    "intro_pattern = r'\\b(?:' + '|'.join(introductory_phrases) + r')\\b'\n",
    "\n",
    "with open('filtered_stem_lectures.json', 'r') as file:\n",
    "    stem_data = json.load(file)\n",
    "\n",
    "\n",
    "def extract_main_subject(title):\n",
    "    # Remove introductory phrases\n",
    "    title = re.sub(intro_pattern, '', title, flags=re.IGNORECASE)\n",
    "    # Remove course codes or other content in parentheses\n",
    "    title = re.sub(r'\\(.*?\\)', '', title)\n",
    "    # Strip and remove extra whitespace\n",
    "    title = title.strip()\n",
    "    return title\n",
    "\n",
    "\n",
    "for category, lectures in stem_data.items():\n",
    "    for lecture in lectures:\n",
    "        lecture[\"resource_course_title\"] = extract_main_subject(lecture[\"resource_course_title\"])\n",
    "\n",
    "with open('filtered_stem_lectures.json', 'w') as outfile:\n",
    "    json.dump(stem_data, outfile, indent=4)\n",
    "\n",
    "print(\"Final cleaned course titles have been saved to 'filtered_stem_lectures.json'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fdh_yas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
