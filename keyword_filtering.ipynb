{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/kroknes/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered, de-duplicated, and cleaned titles have been saved to 'filtered_stem_lectures.json'\n",
      "Final cleaned course titles have been saved to 'filtered_stem_lectures.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "# Define lecture-related stopwords and patterns to filter out\n",
    "additional_stop_words = {\n",
    "    \"introduction\", \"overview\", \"basics\", \"principles\", \"fundamentals\", \"essentials\",\n",
    "    \"concepts\", \"topics\", \"outline\", \"scope\", \"insights\", \"lecture\", \"session\",\n",
    "    \"class\", \"seminar\", \"discussion\", \"tutorial\", \"workshop\", \"exercise\", \"module\",\n",
    "    \"part\", \"series\", \"unit\", \"goals\", \"objectives\", \"summary\", \"review\", \"highlights\",\n",
    "    \"conclusion\", \"recap\", \"continued\", \"continuation\", \"advanced\", \"update\", \"notes\",\n",
    "    \"refresher\", \"start\", \"beginning\", \"end\", \"final\", \"first\", \"second\", \"third\", \n",
    "    \"perspective\", \"focus\", \"study\", \"methods\", \"approaches\", \"applications\", \"field\",\n",
    "    \"understanding\", \"applications of\", \"in context\", \"applied\", \"introduction to\", \n",
    "    \"explanation\", \"examining\", \"exam\", \"goals\", \"and\", \"quiz\", \"presentation\", \n",
    "    \"presentations\", \"case\", \"cases\", \"bonus\", \"project\", \"projects\", \"problem\",\n",
    "    \"problems\", \"course\", \"courses\", \"solution\", \"solutions\", \"general\", \n",
    "    \"examples\", \"example\", \"lectures\", \"question\", \"questions\", \"answer\", \"answers\",\n",
    "    \"reading\", \"assignment\", \"assignments\", \"definition\", \"definitions\"\n",
    "}\n",
    "all_stopwords = set(stopwords.words(\"english\")).union(additional_stop_words)\n",
    "\n",
    "# Patterns to clean and normalize the titles\n",
    "patterns_to_remove = r\"Lecture\\s*\\d+:|Lecture\\s*\\d+|^(\\d+[\\.\\:\\;\\,\\-\\—\\—]\\s*)\"\n",
    "continuation_pattern = r\"\\b(cont\\.?|contd\\.?|continued)\\b\"\n",
    "parentheses_pattern = r\"\\(.*?\\)\"\n",
    "roman_numeral_pattern = r\"\\b[IVXLCDM]+\\b\"\n",
    "number_pattern = r\"\\b\\d+[\\.\\:\\;\\,]?\\b\"\n",
    "symbol_cleanup_pattern = r\"(?<!\\w)[^\\w\\s/-]|[^\\w\\s/-](?!\\w)\"\n",
    "\n",
    "max_words_per_title = 4\n",
    "\n",
    "with open('lecture_videos_data.json', 'r') as file:\n",
    "    stem_data = json.load(file)\n",
    "\n",
    "# Function to normalize Unicode symbols and replace non-ASCII characters with spaces\n",
    "def normalize_unicode(text):\n",
    "    # Replace known Unicode symbols with ASCII equivalents\n",
    "    text = re.sub(r\"[\\u2013\\u2014\\u2015—]\", \"-\", text)  # Normalize dashes to hyphen\n",
    "    # Normalize and replace non-ASCII characters with a space\n",
    "    text = unicodedata.normalize(\"NFKD\", text)\n",
    "    return \"\".join(c if ord(c) < 128 else \" \" for c in text)  # Replace non-ASCII with space\n",
    "\n",
    "# Function to pre-process and clean the title field, including Unicode normalization\n",
    "def preprocess_title(title):\n",
    "    # Normalize Unicode symbols and replace non-ASCII characters with spaces\n",
    "    title = normalize_unicode(title)\n",
    "    # Remove parentheses content\n",
    "    title = re.sub(parentheses_pattern, \"\", title)\n",
    "    # Remove Roman numerals\n",
    "    title = re.sub(roman_numeral_pattern, \"\", title, flags=re.IGNORECASE)\n",
    "    # Remove standalone numbers and any trailing punctuation\n",
    "    title = re.sub(number_pattern, \"\", title)\n",
    "    # Remove specified patterns and numbers with punctuation\n",
    "    title = re.sub(patterns_to_remove, \"\", title, flags=re.IGNORECASE)\n",
    "    return title.strip()\n",
    "\n",
    "# Function to filter and separate keywords within title fields, splitting only by commas, colons, and semicolons\n",
    "def filter_keywords(title):\n",
    "    title = preprocess_title(title)  # Preprocess the title with Unicode handling\n",
    "    title_parts = re.split(r'[,:;]', title)  # Split by punctuation to separate distinct concepts\n",
    "    filtered_parts = []\n",
    "    for part in title_parts:\n",
    "        # Remove isolated dots and leading/trailing hyphens within each part\n",
    "        part = re.sub(r\"^\\.\\s*\", \"\", part).strip()\n",
    "        part = re.sub(r\"^-+|-+$\", \"\", part).strip()  # Remove leading/trailing hyphens\n",
    "        filtered_words = [\n",
    "            re.sub(symbol_cleanup_pattern, \"\", word) for word in part.split()\n",
    "            if word.lower() not in all_stopwords and not re.search(r\"[?!]$\", word)\n",
    "        ]\n",
    "        # Rejoin words if they are below the word count threshold\n",
    "        if filtered_words and len(filtered_words) <= max_words_per_title:\n",
    "            filtered_parts.append(\" \".join(filtered_words))\n",
    "    return filtered_parts\n",
    "\n",
    "# Function to remove words starting or ending with punctuation\n",
    "def remove_punctuated_words(title_list):\n",
    "    cleaned_title_list = [\n",
    "        word for word in title_list if not re.search(r\"^[^\\w]|[^\\w]$\", word)\n",
    "    ]\n",
    "    return cleaned_title_list\n",
    "\n",
    "# Process JSON data to filter out keywords in the title field and exclude continuation entries\n",
    "unique_lectures = {}\n",
    "for category, lectures in stem_data.items():\n",
    "    filtered_lectures = []\n",
    "    seen_titles = set()\n",
    "    for lecture in lectures:\n",
    "        if re.search(continuation_pattern, lecture[\"title\"], re.IGNORECASE):  # Skip continuation markers\n",
    "            continue\n",
    "        filtered_title_list = filter_keywords(lecture[\"title\"])  # Filter keywords\n",
    "        filtered_title_list = remove_punctuated_words(filtered_title_list)  # Remove punctuated words\n",
    "        if not filtered_title_list:  # Exclude lecture entry if all titles were removed\n",
    "            continue\n",
    "        unique_key = (lecture[\"resource_course_title\"], tuple(filtered_title_list))\n",
    "        if unique_key not in seen_titles:\n",
    "            lecture[\"title\"] = filtered_title_list\n",
    "            filtered_lectures.append(lecture)\n",
    "            seen_titles.add(unique_key)\n",
    "    unique_lectures[category] = filtered_lectures\n",
    "\n",
    "with open('filtered_stem_lectures.json', 'w') as outfile:\n",
    "    json.dump(unique_lectures, outfile, indent=4)\n",
    "print(\"Filtered, de-duplicated, and cleaned titles have been saved to 'filtered_stem_lectures.json'\")\n",
    "\n",
    "# Process `resource_course_title` field in the saved filtered data\n",
    "introductory_phrases = [\n",
    "    r\"Introduction to\", r\"Principles of\", r\"Basics of\", r\"Overview of\",\n",
    "    r\"Essentials of\", r\"Introduction\", r\"Intro to\", r\"Introductory\", r\"Foundations of\"\n",
    "]\n",
    "intro_pattern = r'\\b(?:' + '|'.join(introductory_phrases) + r')\\b'\n",
    "\n",
    "with open('filtered_stem_lectures.json', 'r') as file:\n",
    "    stem_data = json.load(file)\n",
    "\n",
    "# Function to clean and extract main subject from `resource_course_title`\n",
    "def extract_main_subject(title):\n",
    "    title = re.sub(intro_pattern, '', title, flags=re.IGNORECASE)\n",
    "    title = re.sub(r'\\(.*?\\)', '', title)  # Remove course codes or other content in parentheses\n",
    "    return title.strip()\n",
    "\n",
    "for category, lectures in stem_data.items():\n",
    "    for lecture in lectures:\n",
    "        lecture[\"resource_course_title\"] = extract_main_subject(lecture[\"resource_course_title\"])\n",
    "\n",
    "with open('filtered_stem_lectures.json', 'w') as outfile:\n",
    "    json.dump(stem_data, outfile, indent=4)\n",
    "print(\"Final cleaned course titles have been saved to 'filtered_stem_lectures.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fdh_yas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
